{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import torch\n",
    "\n",
    "import networks\n",
    "from datasets import ImageDataset\n",
    "\n",
    "from plotAllLosses import plotLosses, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateImgs(metaData):\n",
    "    if len(metaData.shape) == 4:\n",
    "        return metaData[:,0:3]\n",
    "    elif len(metaData.shape) == 3:\n",
    "        return metaData[0:3]\n",
    "    else:\n",
    "        print(\"Cannot seperate images from a tensor with shape of \" + str(metaData.shape))\n",
    "def seperateMetas(metaData):\n",
    "    if len(metaData.shape) == 4:\n",
    "        return metaData[:,3:8]\n",
    "    elif len(metaData.shape) == 3:\n",
    "        return metaData[3:8]\n",
    "    else:\n",
    "        print(\"Cannot seperate metas from a tensor with shape of \" + str(metaData.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb32486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorPath(epoch):\n",
    "    return saved_model_path + model_name + (\"_generator_%d.pth\" % epoch)\n",
    "def discriminatorPath(epoch):\n",
    "    return saved_model_path + model_name + (\"_discriminator_%d.pth\" % epoch)\n",
    "def baseGeneratorPath():\n",
    "    return saved_model_path + srgan_name + (\"_generator.pth\")\n",
    "def autoencoderPath():\n",
    "    return saved_model_path + encoder_name + (\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073135a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(imgs, epoch):\n",
    "    batch_size = 8 if imgs[0].shape[0] > 8 else imgs[0].shape[0]\n",
    "    grid_imgs = []\n",
    "    for img_seq in imgs:\n",
    "        grid_imgs.append(make_grid(img_seq[0:batch_size], nrow=1, normalize=False))\n",
    "    imgs_all = torch.cat(grid_imgs, dim=-1)\n",
    "    save_image(imgs_all, sample_path + model_name + (\"_%d.png\" % epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c32352",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "hr_shape       = (256,256)\n",
    "dataset_root   = \"../Dataset/\"\n",
    "trainset_name  = \"QuickRender_train/\"\n",
    "testset_name   = \"QuickRender_test/\"\n",
    "batch_size     = 16\n",
    "starting_epoch = 0\n",
    "epochs         = 200\n",
    "\n",
    "saved_model_path = \"../Checkpoints/\"\n",
    "model_name       = \"MetaSRGAN\"\n",
    "encoder_name     = \"DNO_Autoencoder\"\n",
    "srgan_name       = \"SRGAN\"\n",
    "\n",
    "sample_path = \"../Samples/TrainingSamples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator         = networks.GeneratorResNet()\n",
    "baseGenerator     = networks.GeneratorSlowNet()\n",
    "discriminator     = networks.Discriminator(input_shape=(3, *hr_shape))\n",
    "feature_extractor = networks.FeatureExtractor()\n",
    "encoder           = networks.MetaAutoencoderTail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if starting_epoch > 0:\n",
    "    generator.load_state_dict(torch.load(generatorPath(starting_epoch)))\n",
    "    discriminator.load_state_dict(torch.load(discriminatorPath(starting_epoch)))\n",
    "encoder.load_state_dict(torch.load(autoencoderPath()))\n",
    "encoder.eval()\n",
    "baseGenerator.load_state_dict(torch.load(baseGeneratorPath()))\n",
    "baseGenerator.eval()\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be493004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss functions\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_content = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeedd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    print(\"Training on GPU\")\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    baseGenerator = baseGenerator.cuda()\n",
    "    encoder = encoder.cuda()\n",
    "    feature_extractor = feature_extractor.cuda()\n",
    "    criterion_GAN = criterion_GAN.cuda()\n",
    "    criterion_content = criterion_content.cuda()\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60632c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizers\n",
    "learning_rate = 0.0002\n",
    "optimizer_G  = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D  = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8550855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=ImageDataset(dataset_root + trainset_name, hr_shape), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=ImageDataset(dataset_root + testset_name, hr_shape), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatorTrainLosses = []\n",
    "generatorTestLosses  = []\n",
    "discriminatorTrainLosses = []\n",
    "discriminatorTestLosses  = []\n",
    "generatorDeltas = []\n",
    "discriminatorDeltas = []\n",
    "\n",
    "lossLabels = [\"Generator Train\", \"Generator Test\", \"Generator Delta\"]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "depth, hr_depth, normal, hr_normal, obj, hr_obj, hr_imgs, hr_inf = None, None, None, None, None, None, None, None\n",
    "\n",
    "for epoch in range(starting_epoch, epochs):\n",
    "    torch.set_grad_enabled(True)\n",
    "    holdGenLosses     = []\n",
    "    holdDisLosses     = []\n",
    "    for i, imgs in enumerate(train_loader):\n",
    "        lr_imgs = Variable(seperateImgs(imgs[\"lr\"]).type(Tensor))\n",
    "        hr_imgs = Variable(seperateImgs(imgs[\"hr\"]).type(Tensor))\n",
    "        lr_metas = Variable(seperateMetas(imgs[\"lr\"]).type(Tensor))\n",
    "        hr_metas = Variable(seperateMetas(imgs[\"hr\"]).type(Tensor))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((lr_imgs.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((lr_imgs.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        \n",
    "        depth  = lr_metas[:, 0:1]\n",
    "        normal = lr_metas[:, 1:4]\n",
    "        obj    = lr_metas[:, 4:5]\n",
    "        b, c, h, w = lr_metas.shape\n",
    "        \n",
    "        depth  = torch.cat((depth, depth, depth), 1)\n",
    "        obj    = torch.cat((obj, obj, obj), 1)\n",
    "        \n",
    "        depth  = baseGenerator(depth)\n",
    "        normal = baseGenerator(normal)\n",
    "        obj    = baseGenerator(obj)\n",
    "        \n",
    "        hr_depth  = hr_metas[:, 0:1]\n",
    "        hr_normal = hr_metas[:, 1:4]\n",
    "        hr_obj    = hr_metas[:, 4:5]\n",
    "        \n",
    "        hr_depth  = torch.cat((hr_depth, hr_depth, hr_depth), 1)\n",
    "        hr_obj    = torch.cat((hr_obj, hr_obj, hr_obj), 1)\n",
    "        \n",
    "        # =============== construct metas =======================\n",
    "        depth = depth[:, 0:1]\n",
    "        obj   = obj[:, 0:1]\n",
    "        hr_metas = torch.cat((depth, normal, obj), 1)\n",
    "        \n",
    "        meta_vec = encoder(hr_metas)\n",
    "        \n",
    "        #========== Train Generator =====================\n",
    "        optimizer_G.zero_grad()\n",
    "        #Inference\n",
    "        hr_inf = generator(lr_imgs, meta_vec)\n",
    "        #Adversarial loss\n",
    "        loss_GAN = criterion_GAN(discriminator(hr_inf), valid)\n",
    "        #Content loss\n",
    "        inf_features  = feature_extractor(hr_inf)\n",
    "        real_features = feature_extractor(hr_imgs)\n",
    "        loss_content  = criterion_content(inf_features, real_features.detach())\n",
    "        #total loss\n",
    "        loss_G = loss_content + 1e-3 * loss_GAN\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        #========= Train Discriminator ==================\n",
    "        optimizer_D.zero_grad()\n",
    "        #loss of real and fake images\n",
    "        loss_real = criterion_GAN(discriminator(hr_imgs), valid)\n",
    "        loss_fake = criterion_GAN(discriminator(hr_inf.detach()), fake)\n",
    "        #total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        holdGenLosses.append(loss_G.item())\n",
    "        holdDisLosses.append(loss_D.item())\n",
    "    \n",
    "    if epoch > 0:\n",
    "        generatorTrainLosses.append(avg_loss(holdGenLosses))\n",
    "        discriminatorTrainLosses.append(avg_loss(holdDisLosses))\n",
    "    \n",
    "    torch.save(generator.state_dict(), generatorPath(epoch+1))\n",
    "    torch.save(discriminator.state_dict(), discriminatorPath(epoch+1))\n",
    "    \n",
    "    save_sample([depth, hr_depth, normal, hr_normal, obj, hr_obj, hr_inf, hr_imgs], epoch + 1)\n",
    "    \n",
    "    torch.set_grad_enabled(False)\n",
    "    holdGenLosses     = []\n",
    "    holdSlowGenLosses = []\n",
    "    for i, imgs in enumerate(test_loader):\n",
    "        lr_imgs = Variable(seperateImgs(imgs[\"lr\"]).type(Tensor))\n",
    "        hr_imgs = Variable(seperateImgs(imgs[\"hr\"]).type(Tensor))\n",
    "        lr_metas = Variable(seperateMetas(imgs[\"lr\"]).type(Tensor))\n",
    "        hr_metas = Variable(seperateMetas(imgs[\"hr\"]).type(Tensor))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((lr_imgs.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((lr_imgs.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        \n",
    "        depth  = lr_metas[:, 0:1]\n",
    "        normal = lr_metas[:, 1:4]\n",
    "        obj    = lr_metas[:, 4:5]\n",
    "        b, c, h, w = lr_metas.shape\n",
    "        \n",
    "        depth  = torch.cat((depth, depth, depth), 1)\n",
    "        obj    = torch.cat((obj, obj, obj), 1)\n",
    "        \n",
    "        depth  = baseGenerator(depth)\n",
    "        normal = baseGenerator(normal)\n",
    "        obj    = baseGenerator(obj)\n",
    "        \n",
    "        #============= Construct Metas =======================\n",
    "        depth = depth[:, 0:1]\n",
    "        obj   = obj[:, 0:1]\n",
    "        hr_metas = torch.cat((depth, normal, obj), 1)\n",
    "        \n",
    "        meta_vec = encoder(hr_metas)\n",
    "        \n",
    "        #========== Train Generator =====================\n",
    "        optimizer_G.zero_grad()\n",
    "        #Inference\n",
    "        hr_inf = generator(lr_imgs, meta_vec)\n",
    "        #Adversarial loss\n",
    "        loss_GAN = criterion_GAN(discriminator(hr_inf), valid)\n",
    "        #Content loss\n",
    "        inf_features  = feature_extractor(hr_inf)\n",
    "        real_features = feature_extractor(hr_imgs)\n",
    "        loss_content  = criterion_content(inf_features, real_features.detach())\n",
    "        #total loss\n",
    "        loss_G = loss_content + 1e-3 * loss_GAN\n",
    "        \n",
    "        #========= Train Discriminator ==================\n",
    "        #loss of real and fake images\n",
    "        loss_real = criterion_GAN(discriminator(hr_imgs), valid)\n",
    "        loss_fake = criterion_GAN(discriminator(hr_inf.detach()), fake)\n",
    "        #total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "        \n",
    "        holdGenLosses.append(loss_G.item())\n",
    "        holdDisLosses.append(loss_D.item())\n",
    "    \n",
    "    generatorTestLosses.append(avg_loss(holdGenLosses))\n",
    "    discriminatorTestLosses.append(avg_loss(holdDisLosses))\n",
    "    if epoch == 0:\n",
    "        generatorTrainLosses.append(generatorTestLosses[-1])\n",
    "        discriminatorTrainLosses.append(discriminatorTestLosses[-1])\n",
    "    generatorDeltas.append(generatorTrainLosses[-1] - generatorTestLosses[-1])\n",
    "    discriminatorDeltas.append(discriminatorTrainLosses[-1] - discriminatorTestLosses[-1])\n",
    "    plotLosses(\n",
    "        \"MetaSRGAN\",\n",
    "        epoch+1,\n",
    "        epochs,\n",
    "        [generatorTrainLosses, generatorTestLosses, generatorDeltas],\n",
    "        lossLabels,\n",
    "        start_time\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
